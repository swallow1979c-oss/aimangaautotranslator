import argparse
import base64
import os
import time
import re
from pathlib import Path
from typing import Optional, Union, Callable, Dict, Any
import sys
import cv2
from PIL import Image
import torch

from core.models import (
    DetectionConfig,
    CleaningConfig,
    TranslationConfig,
    RenderingConfig,
    OutputConfig,
    MangaTranslatorConfig,
)
from .detection import detect_speech_bubbles
from .cleaning import clean_speech_bubbles
from .image_utils import pil_to_cv2, cv2_to_pil, save_image_with_compression
from .translation import call_translation_api_batch, sort_bubbles_by_reading_order
from utils.logging import log_message
from .rendering import render_text_skia

def translate_and_render(
    image_path: Union[str, Path], config: MangaTranslatorConfig, output_path: Optional[Union[str, Path]] = None
):
    """
    Main function to translate manga speech bubbles and render translations using a config object.
    Retries the whole page if Gemini-OCR returns 'No text/empty response'.
    """
    MAX_PAGE_RETRIES = 5  # ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ€Ð°Ð· Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ñ‚ÑŒ Ð·Ð°Ð½Ð¾Ð²Ð¾ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñƒ

    for attempt in range(MAX_PAGE_RETRIES):
        start_time = time.time()
        image_path = Path(image_path)
        verbose = config.verbose
        device = config.device

        log_message(f"Using device: {device}", verbose=verbose)

        try:
            pil_original = Image.open(image_path)
        except FileNotFoundError:
            log_message(f"Error: Input image not found at {image_path}", always_print=True)
            raise
        except Exception as e:
            log_message(f"Error opening image {image_path}: {e}", always_print=True)
            raise

        original_mode = pil_original.mode
        log_message(f"Original image mode: {original_mode}", verbose=verbose)

        desired_format = config.output.output_format
        output_ext_for_mode = Path(output_path).suffix.lower() if output_path else image_path.suffix.lower()

        if desired_format == "jpeg" or (desired_format == "auto" and output_ext_for_mode in [".jpg", ".jpeg"]):
            target_mode = "RGB"
        else:
            target_mode = "RGBA"
        log_message(
            f"Target image mode determined as: {target_mode} "
            f"(based on format: {desired_format}, output_ext: {output_ext_for_mode})",
            verbose=verbose,
        )

        pil_image_processed = pil_original
        if pil_image_processed.mode != target_mode:
            if target_mode == "RGB":
                if (
                    pil_image_processed.mode == "RGBA"
                    or pil_image_processed.mode == "LA"
                    or (pil_image_processed.mode == "P" and "transparency" in pil_image_processed.info)
                ):
                    log_message(f"Converting {pil_image_processed.mode} to RGB (flattening transparency)", verbose=verbose)
                    background = Image.new("RGB", pil_image_processed.size, (255, 255, 255))
                    try:
                        mask = None
                        if pil_image_processed.mode == "RGBA":
                            mask = pil_image_processed.split()[3]
                        elif pil_image_processed.mode == "LA":
                            mask = pil_image_processed.split()[1]
                        elif pil_image_processed.mode == "P" and "transparency" in pil_image_processed.info:
                            temp_rgba = pil_image_processed.convert("RGBA")
                            mask = temp_rgba.split()[3]

                        if mask:
                            background.paste(pil_image_processed, mask=mask)
                            pil_image_processed = background
                        else:
                            pil_image_processed = pil_image_processed.convert("RGB")
                    except Exception as paste_err:
                        log_message(
                            f"Warning: Error during RGBA/LA/P -> RGB conversion paste: {paste_err}. "
                            f"Trying alpha_composite.",
                            verbose=verbose,
                        )
                        try:
                            background_comp = Image.new("RGB", pil_image_processed.size, (255, 255, 255))
                            img_rgba_for_composite = (
                                pil_image_processed
                                if pil_image_processed.mode == "RGBA"
                                else pil_image_processed.convert("RGBA")
                            )
                            pil_image_processed = Image.alpha_composite(
                                background_comp.convert("RGBA"), img_rgba_for_composite
                            ).convert("RGB")
                            log_message("Successfully used alpha_composite for RGB conversion.", verbose=verbose)
                        except Exception as composite_err:
                            log_message(
                                f"Warning: alpha_composite also failed: {composite_err}. Using simple convert.",
                                verbose=verbose,
                            )
                            pil_image_processed = pil_image_processed.convert("RGB")
                else:
                    log_message(f"Converting {pil_image_processed.mode} to RGB", verbose=verbose)
                    pil_image_processed = pil_image_processed.convert("RGB")
            elif target_mode == "RGBA":
                log_message(f"Converting {pil_image_processed.mode} to RGBA", verbose=verbose)
                pil_image_processed = pil_image_processed.convert("RGBA")

        original_cv_image = pil_to_cv2(pil_image_processed)

        # --- Encode Full Image for Context ---
        full_image_b64 = None
        try:
            is_success, buffer = cv2.imencode(".jpg", original_cv_image)
            if not is_success:
                raise ValueError("Full image encoding to JPEG failed")
            full_image_b64 = base64.b64encode(buffer).decode("utf-8")
            log_message("Encoded full image for translation context.", verbose=verbose)
        except Exception as e:
            log_message(f"Error encoding full image to base64: {e}. Translation might lack context.", always_print=True)

        # --- Detection ---
        log_message("Detecting speech bubbles...", verbose=verbose)
        try:
            bubble_data = detect_speech_bubbles(
                image_path, config.detector_model_path, config.detection.confidence, verbose=verbose, device=device
            )
        except Exception as e:
            log_message(f"Error during bubble detection: {e}. Proceeding without bubbles.", always_print=True)
            bubble_data = []

        final_image_to_save = pil_image_processed

        if not bubble_data:
            log_message("No speech bubbles detected or detection failed.", always_print=True)
        else:
            log_message(f"Detected {len(bubble_data)} potential bubbles.", verbose=verbose)

            # --- Cleaning ---
            try:
                cleaned_image_cv, processed_bubbles_info = clean_speech_bubbles(
                    image_path=image_path,
                    cleaner_model_path=config.cleaner_model_path,
                    confidence=config.detection.confidence,
                    pre_computed_detections=bubble_data,  # bbox Ð¾Ñ‚ Ð´ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€Ð°
                    device=device,
                    dilation_kernel_size=config.cleaning.dilation_kernel_size,
                    dilation_iterations=config.cleaning.dilation_iterations,
                    use_otsu_threshold=config.cleaning.use_otsu_threshold,
                    min_contour_area=config.cleaning.min_contour_area,
                    closing_kernel_size=config.cleaning.closing_kernel_size,
                    closing_iterations=config.cleaning.closing_iterations,
                    closing_kernel_shape=config.cleaning.closing_kernel_shape,
                    constraint_erosion_kernel_size=config.cleaning.constraint_erosion_kernel_size,
                    constraint_erosion_iterations=config.cleaning.constraint_erosion_iterations,
                    verbose=verbose,
                )
            except Exception as e:
                log_message(
                    f"Error during bubble cleaning: {e}. Proceeding with uncleaned image.",
                    always_print=True
                )
                cleaned_image_cv = original_cv_image.copy()
                processed_bubbles_info = []

            pil_cleaned_image = cv2_to_pil(cleaned_image_cv)
            if pil_cleaned_image.mode != target_mode:
                pil_cleaned_image = pil_cleaned_image.convert(target_mode)
            final_image_to_save = pil_cleaned_image

            if not config.cleaning_only:
                # --- Prepare bubble crops + stable IDs ---
                for bubble in bubble_data:
                    x1, y1, x2, y2 = bubble["bbox"]

                    # Ð¡Ñ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ ID Ð´Ð»Ñ Ð±Ð°Ð±Ð»Ð° (Ð½Ð° ÑƒÑ€Ð¾Ð²Ð½Ðµ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ bbox-ÐºÐ¾Ð¾Ñ€Ð´)
                    bubble["id"] = f"{x1}_{y1}_{x2}_{y2}"

                    bubble_image_cv = original_cv_image[y1:y2, x1:x2].copy()
                    try:
                        is_success, buffer = cv2.imencode(".jpg", bubble_image_cv)
                        if not is_success:
                            raise ValueError("cv2.imencode failed")
                        bubble["image_b64"] = base64.b64encode(buffer).decode("utf-8")
                    except Exception as e:
                        bubble["image_b64"] = None
                        log_message(f"Error encoding bubble: {e}", always_print=True)

                valid_bubble_data = [b for b in bubble_data if b.get("image_b64")]
                if valid_bubble_data and full_image_b64:
                    H, W = original_cv_image.shape[:2]
                    sorted_bubble_data = sort_bubbles_by_reading_order(
                        valid_bubble_data,
                        H,
                        W,
                        config.translation.reading_direction,
                    )

                    # 2) Ð“Ð¾Ñ‚Ð¾Ð²Ð¸Ð¼ Ð±Ð°Ñ‚Ñ‡ Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº ID Ð² Ñ‚Ð¾Ð¼ Ð¶Ðµ Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ
                    bubble_images_b64 = [b["image_b64"] for b in sorted_bubble_data]
                    bubble_ids = [b["id"] for b in sorted_bubble_data]

                    # 3) Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ Ñ ID-Ð¼Ð°Ñ€ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹ (Ð²ÐµÑ€Ð½Ñ‘Ñ‚ dict id->text)
                    try:
                        translations_by_id = call_translation_api_batch(
                            config=config.translation,
                            images_b64=bubble_images_b64,
                            full_image_b64=full_image_b64,
                            debug=verbose,
                            bubble_ids=bubble_ids,  # <<< Ð’ÐÐ–ÐÐž: Ð½Ð¾Ð²Ñ‹Ð¹ Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚
                        )
                    except RuntimeError as e:
                        if "Ð’ÑÐµ Gemini ÐºÐ»ÑŽÑ‡Ð¸ Ð¸ÑÑ‡ÐµÑ€Ð¿Ð°Ð½Ñ‹" in str(e):
                            log_message("ðŸš¨ Ð’ÑÐµ ÐºÐ»ÑŽÑ‡Ð¸ Gemini Ð¸ÑÑ‡ÐµÑ€Ð¿Ð°Ð½Ñ‹. ÐŸÑ€ÐµÐºÑ€Ð°Ñ‰Ð°ÐµÐ¼ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ ÑÐºÑ€Ð¸Ð¿Ñ‚Ð°.", always_print=True)
                            raise RuntimeError("Ð’ÑÐµ Gemini ÐºÐ»ÑŽÑ‡Ð¸ Ð¸ÑÑ‡ÐµÑ€Ð¿Ð°Ð½Ñ‹/Ð·Ð°Ð¿Ñ€ÐµÑ‰ÐµÐ½Ñ‹. Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½.")
                        else:
                            raise
                    except Exception as e:
                        log_message(f"Error during API translation: {e}", always_print=True)
                        translations_by_id = {bid: "[Translation Error]" for bid in bubble_ids}

                    # 4) ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½Ð° Â«Ð¿ÑƒÑÑ‚Ñ‹Ðµ/Ð¾ÑˆÐ¸Ð±Ð¾Ñ‡Ð½Ñ‹ÐµÂ» Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹
                    error_strings = [
                        "[Gemini-OCR: No text/empty response]",
                        "[Gemini-Translate: No text/empty response]",
                        "[OCR FAILED]",
                        "[Translation Error]",
                        "[Gemini: OCR call failed/blocked]"
                    ]
                    values = list(translations_by_id.values()) if isinstance(translations_by_id, dict) else (translations_by_id or [])
                    if any(isinstance(v, str) and any(v.strip().startswith(es) for es in error_strings) for v in values):
                        if attempt < MAX_PAGE_RETRIES - 1:
                            log_message(
                                f"[Retry {attempt+1}] Gemini empty/failed response detected on {image_path}, retrying...",
                                always_print=True,
                            )
                            time.sleep(1)
                            continue
                        else:
                            log_message(
                                f"[Retry {attempt+1}] Max retries reached, proceeding with available translations...",
                                always_print=True,
                            )


                    # 5) ÐœÐ°Ð¿Ð¿Ð¸Ð¼ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´Ñ‹ ÐšÐÐ–Ð”ÐžÐœÐ£ Ð±Ð°Ð±Ð»Ñƒ ÐŸÐž ID (Ð´Ð°Ð¶Ðµ ÐµÑÐ»Ð¸ Ð¿ÐµÑ€ÐµÐ²Ð¾Ð´ Ð¿ÑƒÑÑ‚Ð¾Ð¹)
                    for b in sorted_bubble_data:
                        t = translations_by_id.get(b["id"], "")
                        b["translation"] = t if isinstance(t, str) else ""

                    # 6) Ð ÐµÐ½Ð´ÐµÑ€Ð¸Ð¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð½Ñ‹Ðµ
                    for bubble in sorted_bubble_data:
                        text = bubble.get("translation", "")
                        if not text or text.startswith("[Translation Error]"):
                            continue

                        bbox = bubble["bbox"]

                        rendered_image, success = render_text_skia(
                            pil_image=pil_cleaned_image,
                            text=text,
                            bbox=bbox,
                            lir_bbox=None,
                            cleaned_mask=None,
                            bubble_color_bgr=(255,255,255),
                            font_dir=config.rendering.font_dir,
                            min_font_size=config.rendering.min_font_size,
                            max_font_size=config.rendering.max_font_size,
                            line_spacing_mult=config.rendering.line_spacing,
                            use_subpixel_rendering=config.rendering.use_subpixel_rendering,
                            font_hinting=config.rendering.font_hinting,
                            use_ligatures=config.rendering.use_ligatures,
                            verbose=verbose,
                        )
                        if success:
                            pil_cleaned_image = rendered_image
                            final_image_to_save = pil_cleaned_image

        # --- Save Output ---
        if output_path:
            if final_image_to_save.mode != target_mode:
                final_image_to_save = final_image_to_save.convert(target_mode)
            save_image_with_compression(
                final_image_to_save,
                output_path,
                jpeg_quality=config.output.jpeg_quality,
                png_compression=config.output.png_compression,
                verbose=verbose,
            )

        end_time = time.time()
        log_message(f"Processing finished in {end_time - start_time:.2f} seconds.", always_print=True)
        return final_image_to_save

    # ÐµÑÐ»Ð¸ Ð²ÑÐµ Ð¿Ð¾Ð¿Ñ‹Ñ‚ÐºÐ¸ Ð½ÐµÑƒÐ´Ð°Ñ‡Ð½Ñ‹
    log_message(f"Page {image_path} failed after {MAX_PAGE_RETRIES} retries.", always_print=True)
    return pil_original

def natural_sort_key(path: Path):
    return [int(text) if text.isdigit() else text.lower()
            for text in re.split(r'(\d+)', path.name)]

def batch_translate_images(
    input_dir: Union[str, Path],
    config: MangaTranslatorConfig,
    output_dir: Optional[Union[str, Path]] = None,
    progress_callback: Optional[Callable[[float, str], None]] = None,
) -> Dict[str, Any]:
    """
    Process all images in a directory (recursively) using a configuration object.
    Files in each folder are processed fully before moving to the next folder.
    Skips already processed files inside output folder.
    """
    input_dir = Path(input_dir)
    if not input_dir.is_dir():
        log_message(f"Input path '{input_dir}' is not a directory", always_print=True)
        return {"success_count": 0, "error_count": 0, "errors": {}}

    if output_dir:
        output_dir = Path(output_dir)
    else:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_dir = Path("./output") / timestamp

    os.makedirs(output_dir, exist_ok=True)

    image_extensions = [".jpg", ".jpeg", ".png", ".webp"]
    results = {"success_count": 0, "error_count": 0, "errors": {}}
    total_images = 0

    # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ (Ð±ÐµÐ· output)
    def count_images(folder: Path) -> int:
        if folder.resolve() == output_dir.resolve():
            return 0
        count = sum(1 for f in folder.iterdir() if f.is_file() and f.suffix.lower() in image_extensions)
        for sub in folder.iterdir():
            if sub.is_dir() and sub.resolve() != output_dir.resolve():
                count += count_images(sub)
        return count

    total_images = count_images(input_dir)
    if total_images == 0:
        log_message(f"No image files found in '{input_dir}'", always_print=True)
        return results

    start_batch_time = time.time()
    log_message(f"Starting batch processing of {total_images} images...", always_print=True)
    if progress_callback:
        progress_callback(0.0, f"Starting batch processing of {total_images} images...")

    processed_count = 0

    # ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ€ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
    def process_folder(folder: Path):
        nonlocal processed_count
        if folder.resolve() == output_dir.resolve():
            return

        # Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ñ„Ð°Ð¹Ð»Ñ‹ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ð¿Ð°Ð¿ÐºÐ¸
        files = sorted(
            [f for f in folder.iterdir() if f.is_file() and f.suffix.lower() in image_extensions],
            key=natural_sort_key
        )
        for img_path in files:
            try:
                if progress_callback:
                    progress_callback(processed_count / total_images,
                                      f"Processing image {processed_count + 1}/{total_images}: {img_path.name}")

                # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ
                original_ext = img_path.suffix.lower()
                desired_format = config.output.output_format
                if desired_format == "jpeg":
                    output_ext = ".jpg"
                elif desired_format == "png":
                    output_ext = ".png"
                elif desired_format == "auto":
                    output_ext = original_ext
                else:
                    output_ext = original_ext

                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ð¿Ð°Ð¿Ð¾Ðº
                rel_path = img_path.relative_to(input_dir).parent
                target_dir = output_dir / rel_path
                target_dir.mkdir(parents=True, exist_ok=True)

                output_path = target_dir / f"{img_path.stem}{output_ext}"
                log_message(f"Processing {img_path}", always_print=True)

                translate_and_render(img_path, config, output_path)
                results["success_count"] += 1

            except Exception as e:
                log_message(f"Error processing {img_path}: {str(e)}", always_print=True)
                results["error_count"] += 1
                results["errors"][str(img_path)] = str(e)

            processed_count += 1
            if progress_callback:
                progress_callback(processed_count / total_images,
                                  f"Completed {processed_count}/{total_images} images")

        # ÐŸÐ¾Ñ‚Ð¾Ð¼ Ñ€ÐµÐºÑƒÑ€ÑÐ¸Ð²Ð½Ð¾ Ð¿Ð¾Ð´Ð¿Ð°Ð¿ÐºÐ¸
        subdirs = sorted([d for d in folder.iterdir() if d.is_dir()], key=natural_sort_key)
        for subdir in subdirs:
            if subdir.resolve() != output_dir.resolve():
                process_folder(subdir)

    process_folder(input_dir)

    if progress_callback:
        progress_callback(1.0, "Processing complete")

    end_batch_time = time.time()
    total_batch_time = end_batch_time - start_batch_time
    seconds_per_image = total_batch_time / total_images if total_images > 0 else 0

    log_message(
        f"\nBatch processing complete: {results['success_count']} of {total_images} images processed "
        f"in {total_batch_time:.2f} seconds ({seconds_per_image:.2f} seconds/image).\n",
        always_print=True,
    )
    if results["error_count"] > 0:
        log_message(f"Failed to process {results['error_count']} images.", always_print=True)
        for filename, error_msg in results["errors"].items():
            log_message(f"  - {filename}: {error_msg}", always_print=True)

    return results

def _load_gemini_keys_from_env() -> list[str]:
    raw = os.environ.get("GEMINI_API_KEYS", "")
    return [k.strip() for k in re.split(r"[,\s]+", raw) if k.strip()]

def main():
    parser = argparse.ArgumentParser(description="Translate manga/comic speech bubbles using a configuration approach")
    parser.add_argument("--input", type=str, required=True, help="Path to input image or directory (if using --batch)")
    parser.add_argument(
        "--output", type=str, required=False, help="Path to save the translated image or directory (if using --batch)"
    )
    parser.add_argument("--batch", action="store_true", help="Process all images in the input directory")
    parser.add_argument("--detector-model", type=str, default="/content/aimangaautotranslator/models/comic-speech-bubble-detector.pt", help="YOLO model for detecting speech bubbles")
    parser.add_argument("--cleaner-model", type=str, default="/content/aimangaautotranslator/models/yolov8m_seg-speech-bubble.pt", help="YOLO model for cleaning bubbles (removing text)")
    # --- Provider and API Key Arguments ---
    parser.add_argument(
        "--provider",
        type=str,
        default="Gemini",
        choices=["Gemini", "OpenAI", "Anthropic", "OpenRouter", "OpenAI-Compatible"],
        help="LLM provider to use for translation",
    )
    parser.add_argument(
        "--gemini-api-key",
        type=str,
        default=None,
        help="Gemini API key (overrides GOOGLE_API_KEY env var if --provider is Gemini)",
    )
    parser.add_argument(
        "--openai-api-key",
        type=str,
        default=None,
        help="OpenAI API key (overrides OPENAI_API_KEY env var if --provider is OpenAI)",
    )
    parser.add_argument(
        "--anthropic-api-key",
        type=str,
        default=None,
        help="Anthropic API key (overrides ANTHROPIC_API_KEY env var if --provider is Anthropic)",
    )
    parser.add_argument(
        "--openrouter-api-key",
        type=str,
        default=None,
        help="OpenRouter API key (overrides OPENROUTER_API_KEY env var if --provider is OpenRouter)",
    )
    parser.add_argument(
        "--openai-compatible-url",
        type=str,
        default="http://localhost:11434/v1",
        help="Base URL for the OpenAI-Compatible endpoint (e.g., http://localhost:11434/v1)",
    )
    parser.add_argument(
        "--openai-compatible-api-key",
        type=str,
        default=None,
        help="Optional API key for the OpenAI-Compatible endpoint (overrides OPENAI_COMPATIBLE_API_KEY env var)",
    )
    parser.add_argument(
        "--model-name",
        type=str,
        default=None,
        help="Model name for the selected provider (e.g., 'gemini-2.0-flash'). "
        "If not provided, a default will be attempted based on the provider.",
    )
    parser.add_argument("--font-dir", type=str, default="./fonts", help="Directory containing font files")
    parser.add_argument("--input-language", type=str, default="Japanese", help="Source language")
    parser.add_argument("--output-language", type=str, default="English", help="Target language")
    parser.add_argument("--conf", type=float, default=0.35, help="Confidence threshold for detection")
    parser.add_argument(
        "--reading-direction",
        type=str,
        default="rtl",
        help="Reading direction for sorting bubbles (rtl or ltr)"
    )
    # Cleaning args
    parser.add_argument("--dilation-kernel-size", type=int, default=7, help="ROI Dilation Kernel Size")
    parser.add_argument("--dilation-iterations", type=int, default=1, help="ROI Dilation Iterations")
    parser.add_argument(
        "--use-otsu-threshold",
        action="store_true",
        help="Use Otsu's method for thresholding instead of the fixed value (210)",
    )
    parser.add_argument("--min-contour-area", type=int, default=50, help="Min Bubble Contour Area")
    parser.add_argument("--closing-kernel-size", type=int, default=7, help="Mask Closing Kernel Size")
    parser.add_argument("--closing-iterations", type=int, default=1, help="Mask Closing Iterations")
    parser.add_argument(
        "--constraint-erosion-kernel-size", type=int, default=9, help="Edge Constraint Erosion Kernel Size"
    )
    parser.add_argument(
        "--constraint-erosion-iterations", type=int, default=1, help="Edge Constraint Erosion Iterations"
    )
    # Translation args
    parser.add_argument("--temperature", type=float, default=0.1, help="Controls randomness in output (0.0-2.0)")
    parser.add_argument("--special-instructions", type=str, default=None, help="Add special directions to prompt")
    parser.add_argument("--top-p", type=float, default=0.95, help="Nucleus sampling parameter (0.0-1.0)")
    parser.add_argument("--top-k", type=int, default=1, help="Limits to top k tokens")
    parser.add_argument(
        "--translation-mode",
        type=str,
        default="two-step",
        help="Translation process mode (one-step or two-step)"
    )
    parser.add_argument(
        "--reasoning-effort",
        type=str,
        default="medium",
        choices=["minimal", "low", "medium", "high"],
        help=(
            "Internal reasoning effort for OpenAI reasoning models (o1/o3/o4-mini/gpt-5*). "
            "Note: 'minimal' is only supported by gpt-5 series."
        ),
    )
    # Rendering args
    parser.add_argument("--max-font-size", type=int, default=14, help="Max font size for rendering text.")
    parser.add_argument("--min-font-size", type=int, default=8, help="Min font size for rendering text.")
    parser.add_argument("--line-spacing", type=float, default=1.0, help="Line spacing multiplier for rendered text.")
    # Output args 
    parser.add_argument("--jpeg-quality", type=int, default=95, help="JPEG compression quality (1-100)")
    parser.add_argument("--png-compression", type=int, default=6, help="PNG compression level (0-9)")
    parser.add_argument(
        "--image-mode", type=str, default="RGB", choices=["RGB", "RGBA"], help="Processing image mode (RGB or RGBA)"
    )
    # General args
    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")
    parser.add_argument("--cpu", action="store_true", help="Force CPU usage")
    parser.add_argument(
        "--cleaning-only",
        action="store_true",
        help="Only perform detection and cleaning, skip translation and rendering.",
    )
    parser.add_argument(
        "--enable-thinking",
        action="store_true",
        help="Enable 'thinking' capabilities for Gemini 2.5 Flash models.",
    )
    parser.set_defaults(verbose=False, cpu=False, cleaning_only=False, enable_thinking=False)

    args = parser.parse_args()

    # --- Create Config Object ---
    provider = args.provider
    api_key = None
    api_key_arg_name = ""
    api_key_env_var = ""
    compatible_url = None

    if provider == "Gemini":
        api_key = args.gemini_api_key or os.environ.get("GOOGLE_API_KEY")
        api_key_arg_name = "--gemini-api-key"
        api_key_env_var = "GOOGLE_API_KEY"
        default_model = "gemini-2.0-flash"
    elif provider == "OpenAI":
        api_key = args.openai_api_key or os.environ.get("OPENAI_API_KEY")
        api_key_arg_name = "--openai-api-key"
        api_key_env_var = "OPENAI_API_KEY"
        default_model = "gpt-4o"
    elif provider == "Anthropic":
        api_key = args.anthropic_api_key or os.environ.get("ANTHROPIC_API_KEY")
        api_key_arg_name = "--anthropic-api-key"
        api_key_env_var = "ANTHROPIC_API_KEY"
        default_model = "claude-3.7-sonnet-latest"
    elif provider == "OpenRouter":
        api_key = args.openrouter_api_key or os.environ.get("OPENROUTER_API_KEY")
        api_key_arg_name = "--openrouter-api-key"
        api_key_env_var = "OPENROUTER_API_KEY"
        default_model = "openrouter/auto"
    elif provider == "OpenAI-Compatible":
        compatible_url = args.openai_compatible_url
        api_key = args.openai_compatible_api_key or os.environ.get("OPENAI_COMPATIBLE_API_KEY")
        api_key_arg_name = "--openai-compatible-api-key"
        api_key_env_var = "OPENAI_COMPATIBLE_API_KEY"
        default_model = "default"

    if provider != "OpenAI-Compatible" and not api_key:
        print(
            f"Warning: {provider} API key not provided via {api_key_arg_name} or {api_key_env_var} "
            f"environment variable. Translation will likely fail."
        )

    model_name = args.model_name or default_model
    if not args.model_name:
        print(f"Using default model for {provider}: {model_name}")

    target_device = torch.device("cpu") if args.cpu or not torch.cuda.is_available() else torch.device("cuda")
    print(f"Using {'CPU' if target_device.type == 'cpu' else 'CUDA'} device.")

    use_otsu_config_val = args.use_otsu_threshold

    config = MangaTranslatorConfig(
        detector_model_path=args.detector_model,
        cleaner_model_path=args.cleaner_model,
        verbose=args.verbose,
        device=target_device,
        cleaning_only=args.cleaning_only,
        detection=DetectionConfig(confidence=args.conf),
        cleaning=CleaningConfig(
            dilation_kernel_size=args.dilation_kernel_size,
            dilation_iterations=args.dilation_iterations,
            use_otsu_threshold=use_otsu_config_val,
            min_contour_area=args.min_contour_area,
            closing_kernel_size=args.closing_kernel_size,
            closing_iterations=args.closing_iterations,
            constraint_erosion_kernel_size=args.constraint_erosion_kernel_size,
            constraint_erosion_iterations=args.constraint_erosion_iterations,
        ),
        translation=TranslationConfig(
            provider=provider,
            gemini_api_keys=_load_gemini_keys_from_env() if provider == "Gemini" else None,
            openai_api_key=api_key if provider == "OpenAI" else os.environ.get("OPENAI_API_KEY", ""),
            anthropic_api_key=api_key if provider == "Anthropic" else os.environ.get("ANTHROPIC_API_KEY", ""),
            openrouter_api_key=api_key if provider == "OpenRouter" else os.environ.get("OPENROUTER_API_KEY", ""),
            openai_compatible_url=compatible_url,
            openai_compatible_api_key=(
                api_key if provider == "OpenAI-Compatible" else os.environ.get("OPENAI_COMPATIBLE_API_KEY", "")
            ),
            model_name=model_name,
            temperature=args.temperature,
            special_instructions=args.special_instructions,
            top_p=args.top_p,
            top_k=args.top_k,
            input_language=args.input_language,
            output_language=args.output_language,
            reading_direction=args.reading_direction,
            translation_mode=args.translation_mode,
            enable_thinking=args.enable_thinking,
            reasoning_effort=args.reasoning_effort,
        ),
        rendering=RenderingConfig(
            font_dir=args.font_dir,
            max_font_size=args.max_font_size,
            min_font_size=args.min_font_size,
            line_spacing=args.line_spacing,
        ),
        output=OutputConfig(
            jpeg_quality=args.jpeg_quality, png_compression=args.png_compression, image_mode=args.image_mode
        ),
    )

    # --- Execute --- 
    if args.batch:
        input_path = Path(args.input)
        if not input_path.is_dir():
            print(f"Error: --batch requires --input '{args.input}' to be a directory.")
            exit(1)

        output_dir = Path(args.output) if args.output else None

        if args.output:
            output_dir = Path(args.output)
            if not output_dir.exists():
                print(f"Creating output directory: {output_dir}")
                output_dir.mkdir(parents=True, exist_ok=True)
            elif not output_dir.is_dir():
                print(f"Error: Specified --output '{output_dir}' is not a directory.")
                exit(1)

        batch_translate_images(input_path, config, output_dir)
    else:
        input_path = Path(args.input)
        if not input_path.is_file():
            print(f"Error: Input '{args.input}' is not a valid file.")
            exit(1)

        output_path_arg = args.output
        if not output_path_arg:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            original_ext = input_path.suffix.lower()
            output_ext = original_ext
            output_dir = Path("./output")
            output_dir.mkdir(parents=True, exist_ok=True)
            output_path = output_dir / f"MangaTranslator_{timestamp}{output_ext}"
            print(f"--output not specified, using default: {output_path}")
        else:
            output_path = Path(output_path_arg)
            if not output_path.parent.exists():
                print(f"Creating directory for output file: {output_path.parent}")
                output_path.parent.mkdir(parents=True, exist_ok=True)

        try:
            log_message(f"Processing {input_path}...", always_print=True)
            translate_and_render(input_path, config, output_path)
            log_message(f"Translation complete. Result saved to {output_path}", always_print=True)
        except Exception as e:
            log_message(f"Error processing {input_path}: {e}", always_print=True)


if __name__ == "__main__":
    main()
